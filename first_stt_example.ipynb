{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import azure.cognitiveservices.speech as speechsdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_result(result):\n",
    "    # Checks result.\n",
    "    if result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "        print(\"Recognized: {}\".format(result.text))\n",
    "    elif result.reason == speechsdk.ResultReason.NoMatch:\n",
    "        print(\"No speech could be recognized: {}\".format(result.no_match_details))\n",
    "    elif result.reason == speechsdk.ResultReason.Canceled:\n",
    "        cancellation_details = result.cancellation_details\n",
    "        print(\"Speech Recognition canceled: {}\".format(\n",
    "            cancellation_details.reason))\n",
    "        if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "            print(\"Error details: {}\".format(\n",
    "                cancellation_details.error_details))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 . Create an instance of a speech config\n",
    "   -  Need to get the key from azure speech\n",
    "       - specified subscription key\n",
    "       - service region( see https://aka.ms/speech/sdkregion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_key = 'speech_key_from_azure'\n",
    "service_region = \"koreacentral\"\n",
    "speech_config = speechsdk.SpeechConfig(\n",
    "    subscription=speech_key, region=service_region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create an audio configuration that points to an audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_filename = \"/Users/1110647/projects/azure_speech_test/audio2.wav\"\n",
    "audio_input = speechsdk.AudioConfig(filename=audio_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create a recognizer with the given settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_recognizer = speechsdk.SpeechRecognizer(\n",
    "    speech_config=speech_config, audio_config=audio_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.  STT for single utterance\n",
    " - listning for silence at the end of a speech\n",
    " - maximum of 15 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognizing single utterance...\n",
      "Recognized: Custom speech provides tools that allow you to visually inspect the recognition quality of a model by comparing audio data with the corresponding recognition result from the custom speech portal. You can playback uploaded audio and determine if the provided recognition result is correct this tool allows you to quickly inspect quality of Microsoft's baseline speech to text model or a trained custom model without having to transcribe any audio data.\n"
     ]
    }
   ],
   "source": [
    "print(\"Recognizing single utterance...\")\n",
    "result = speech_recognizer.recognize_once()\n",
    "check_result(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. STT for long-running multi-utterance\n",
    "  - User must subscribe to events to receive recognition results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RECOGNIZED on SpeechRecognitionEventArgs(session_id=64b0cf50e18e409ebdbb89f5f178d1e5, result=SpeechRecognitionResult(result_id=8cd0f9fef07f4e8db7bdee4b0f76aa80, text=\"Custom speech provides tools that allow you to visually inspect the recognition quality of a model by comparing audio data with the corresponding recognition result from the custom speech portal. You can playback uploaded audio and determine if the provided recognition result is correct this tool allows you to quickly inspect quality of Microsoft's baseline speech to text model or a trained custom model without having to transcribe any audio data.\", reason=ResultReason.RecognizedSpeech))\n",
      "CLOSING on SpeechRecognitionCanceledEventArgs(session_id=64b0cf50e18e409ebdbb89f5f178d1e5, result=SpeechRecognitionResult(result_id=b8a78e7849e24c219ee3f6eea0512e93, text=\"\", reason=ResultReason.Canceled))\n",
      "CLOSING on SessionEventArgs(session_id=64b0cf50e18e409ebdbb89f5f178d1e5)\n",
      "Recognized: Custom speech provides tools that allow you to visually inspect the recognition quality of a model by comparing audio data with the corresponding recognition result from the custom speech portal. You can playback uploaded audio and determine if the provided recognition result is correct this tool allows you to quickly inspect quality of Microsoft's baseline speech to text model or a trained custom model without having to transcribe any audio data.\n"
     ]
    }
   ],
   "source": [
    "done = False\n",
    "result = False\n",
    "\n",
    "# Define Callbacks\n",
    "def stop_cb(evt):\n",
    "    \"\"\"callback that signals to stop continuous recognition upon receiving an event `evt`\"\"\"\n",
    "    print('CLOSING on {}'.format(evt))\n",
    "    global done\n",
    "    done = True\n",
    "\n",
    "def return_result(evt):\n",
    "    \"\"\"callback that signals to recognized result upon receiving an event `evt`\"\"\"\n",
    "    print('RECOGNIZED on {}'.format(evt))\n",
    "    global result\n",
    "    result = evt.result\n",
    "\n",
    "# Register Callbacks\n",
    "speech_recognizer.recognized.connect(return_result)\n",
    "speech_recognizer.session_stopped.connect(stop_cb)\n",
    "speech_recognizer.canceled.connect(stop_cb)\n",
    "\n",
    "# Start continuous speech recognition\n",
    "speech_recognizer.start_continuous_recognition()\n",
    "\n",
    "# Wait while finishes processing stt.\n",
    "while not done:\n",
    "    time.sleep(.5)\n",
    "# Stop continuous speech recognition\n",
    "speech_recognizer.stop_continuous_recognition()\n",
    "# Print result\n",
    "check_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
